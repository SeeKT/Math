\documentclass{jsreport}
\input preamble.tex
\begin{document}
\chapter{非協力ゲーム理論の基礎}
\section{ゲーム理論とは}
ゲームは次の3つの要素を持つ．
\begin{itemize}
  \item 複数の行動主体(プレイヤー，エージェント)．
  \item 各主体のとりうる行動(戦略)\footnote{行動はある1つの行動を表し，戦略は，どのようなルールで行動をするかを表す．ゲームにおいては同じ意味で用いられることもある．}の集合．
  \item 各主体の結果に対する評価(利得，効用)\footnote{利得は純粋なスコア，効用な具体的な対象が見えるもののイメージ．}．
\end{itemize}

これらを用いて社会や経済の持つ基本的な特性を表すことができる．複数の主体がどのような行動をとるかによって，全体が決まる．ゲーム理論では，複数の意思決定主体からなる社会の有り様や，主体の行動を研究する\footnote{状況(given)をゲームとして記述することで分析を行う．これを逆に用いると制御系設計ができる．}．

ゲーム理論の中に非協力ゲーム理論がある．これは，各主体の利益が必ずしも一致せず，競合状態にあるものを考えている．つまり，各主体は自分の利益のみを考え，利己的に行動する．ただし，他の主体と完全に対立するときもあれば，他の主体の利益と自分の利益が一致するときもある\footnote{このことから，協力ゲームは非協力ゲームで記述できるとされている．}．

非協力ゲームにおける古典的な仮定として，「完全情報」と「完全合理性」がある．完全情報とは，エージェントがゲームの情報(3要素)を完全に分かっているというものである．完全合理性とは，自身の保有する情報全てを用いて，自身の利益の最大化を実現することである．分散制御では，情報が完全に得られないこともある．近年では，この仮定を緩めることも多い．

\section{純粋戦略}
\subsection{戦略型ゲーム}
戦略型ゲームは次のように定義される．
\begin{screen}
  \begin{defi}[戦略型ゲーム]
  戦略型ゲーム$G = (\mathcal{N}, \mathcal{A}, U)$は次の3要素で定義される．
  \begin{itemize}
    \item $\mathcal{N} = \{1, 2, \ldots, n\}$
    \begin{itemize}
      \item エージェントの集合．
    \end{itemize}
    \item ${\cal A} = \times_{i \in N} {\cal A}_i$
    \begin{itemize}
      \item エージェントの行動プロファイルの集合．
    \end{itemize}
    \item $U \, : \, {\cal A} \rightarrow \mathbb{R}^n$
    \begin{itemize}
      \item 全エージェントの利得関数．
      \item 行動プロファイル$a \in {\cal A}$に対して，利得ベクトル
      $U(a) = (U_1(a), U_2(a), \ldots, U_n(a))$
      を割り当てる．
    \end{itemize}
  \end{itemize}
  \end{defi}
\end{screen}

ただし，
\begin{itemize}
  \item ${\cal A}_i = \{1, 2, \ldots, m_i\}$
  \begin{itemize}
    \item エージェント$i \in N$の選択可能な行動(純粋戦略)の集合(行動インデックス集合)．
  \end{itemize}
  \item $U_i \, : \, {\cal A} \rightarrow \mathbb{R}$
  \begin{itemize}
    \item エージェント$i \in N$の(純粋戦略)利得関数\footnote{定義域が${\cal A}$ (エージェントのの行動プロファイル集合)であることからも，エージェント$i \in N$が得る利得は他のエージェントの行動にも依存することがわかる．}．
    \item 各エージェントは利得を最大化するように戦略を選択する．
  \end{itemize}
\end{itemize}
である．

特に，2人ゲームのときは利得行列$A, B$によってゲームを表現することができる．$e_{m_i}^k \in \mathbb{R}^{m_i}$を第$k$要素が$1$の$m_i$次元単位ベクトルとすると，$k \in {\cal A}_1, h \in {\cal A}_2$に対して，
\begin{equation}
  U_1(k, h) = (e_{m_1}^k)^{\mathrm{T}} A e_{m2}^{h}, \; \; U_2(h, k) = (e_{m_2}^h)^{\mathrm{T}} B e_{m1}^{k} \nonumber
\end{equation}
である．$U_1(k, h)$は，1人目が$k$，2人目が$h$を取ったときの1人目の利得であり，$U_2(h, k)$は1人目が$k$，2人目が$h$を取ったときの2人目の利得である．

ここで，「囚人のジレンマ」を例に2人ゲームの利得行列について説明する．
\begin{itemize}
  \item エージェント
  \begin{itemize}
    \item $N = \{1, 2\}$ (2人の囚人)
  \end{itemize}
  \item 行動集合
  \begin{itemize}
    \item ${\cal A}_1 = {\cal A}_2 = \{協力, 裏切り\}$
  \end{itemize}
  \item 利得\footnote{一般に2人ゲームの利得を表す表においては，行が1人目のエージェント，列が2人目のエージェントを表す．1人目のエージェントを行プレイヤー，列が2人目のエージェントを列プレイヤーともいう．表において，$\cdot,\cdot$は，左側が1人目のエージェントの得る利得，右側が2人目のエージェントの得る利得を表す．}
  \begin{table}[H]
  \centering
    \begin{tabular}{c|c|c}
          & 協力 & 裏切り  \\ \hline
      協力 & $-1, -1$ & $-5, 0$ \\ \hline
      裏切り & $0, -5$ & $-2, -2$ \\
    \end{tabular}
  \end{table}
  \item 利得行列
  \begin{equation}
    A = B = \left(
    \begin{array}{cc}
      -1 & -5 \\
      0 & -2
    \end{array}
    \right) \nonumber
  \end{equation}
\end{itemize}

\subsection{最適反応とナッシュ均衡}
次に，最適反応について定義する．最適反応とは，他のエージェントの行動を固定したとき，エージェント$i$が取りうる全ての行動の中で最も利得が高くなる(つまり，最適な)行動である．最適反応は次のように定義される．
\begin{screen}
  \begin{defi}[最適反応]
    $a_i^{*} \in {\cal A}_i$が$a_{-i} = (a_1, \ldots, a_{i - 1}, a_{i + 1}, \ldots, a_n)$に対する(純粋)最適反応である:
    \begin{equation}
      \forall a_i \in {\cal A}_i, \; U_i(a_i^{*}, a_{-i}) \geq U_i(a_i, a_{-i}) \nonumber
    \end{equation}
  \end{defi}
\end{screen}
この定義は，
\begin{equation}
  U_i(a_i^{*}, a_{-i}) = \max_{a_i \in {\cal A}_i} U_i(a_i, a_{-i}) \nonumber
\end{equation}
と等価である．最適反応は1つとは限らないが，必ず存在する．

ゲーム理論における重要な概念にナッシュ均衡がある．これは，1人だけが行動を変更しても得することがない状況を表す\footnote{ある意味最適解であると考えることもできる．}．ナッシュ均衡は次のように定義される．
\begin{screen}
  \begin{defi}[(純粋戦略)ナッシュ均衡]
    $a^{*} \in {\cal A}$が(純粋戦略)ナッシュ均衡である:
    \begin{equation}
      \forall i \in \mathcal{N}, \forall a_i \in {\cal A}_i, \; \; U_i(a_i^{*}, a_{-i}^{*}) \geq U_i(a_i, a_{-i}^{*}) \nonumber
    \end{equation}
  \end{defi}
\end{screen}
この定義は，
\begin{equation}
  \forall i \in \mathcal{N}, \; \; U_i(a_i^{*}, a_{-i}^{*}) = \max_{a_i \in {\cal A}_i} U_i(a_i, a_{-i}^{*}) \nonumber
\end{equation}
と等価である．ナッシュ均衡は全てのエージェントが純粋戦略最適反応をとることを表す．つまり，全てのエージェントにとって「合理的」な解であり，ナッシュ均衡が実現されれば，全てのエージェントはそこから動かない．
ナッシュ均衡は1つとは限らず，存在しない場合もある．

ナッシュ均衡について，次の3つの2人ゲームの例で説明する．
\paragraph{囚人のジレンマ}
エージェントの集合を$\mathcal{N} = \{1, 2\}$，行動集合を${\cal A}_1 = {\cal A}_2 = \{協力, 裏切り\}$，利得を
\begin{table}[H]
\centering
  \begin{tabular}{c|c|c}
        & 協力 & 裏切り  \\ \hline
    協力 & $-1, -1$ & $-5, 0$ \\ \hline
    裏切り & $0, -5$ & $-2, -2$ \\
  \end{tabular}
\end{table}
とする．

エージェント1(行プレイヤー)について，エージェント2(列プレイヤー)の行動を「協力」に固定したときの最適反応\footnote{表の1列目に注目し，1行目と2行目のエージェント1の利得でより高い値のもの．}は「裏切り」，「裏切り」に固定したときの最適反応\footnote{表の2列目に注目し，1行目と2行目のエージェント1の利得でより高い値のもの．}は「裏切り」である．
エージェント2についても同様に考えると，エージェント1の行動を「協力」に固定したときの最適反応は「裏切り」，「裏切り」に固定したときの最適反応は「裏切り」である．よって，ナッシュ均衡は(裏切り，裏切り)である．

\paragraph{男女の争い}
エージェントの集合を$\mathcal{N} = \{1, 2\}$，行動集合を${\cal A}_1 = {\cal A}_2 = \{ボクシング, バレエ\}$，利得を
\begin{table}[H]
\centering
  \begin{tabular}{c|c|c}
        & ボクシング & バレエ  \\ \hline
    ボクシング & $2, 1$ & $-1, -1$ \\ \hline
    バレエ & $-1, -1$ & $1, 2$ \\
  \end{tabular}
\end{table}
とする．

最適反応は，「ボクシング」に対して「ボクシング」，「バレエ」に対して「バレエ」である．よって，ナッシュ均衡は(ボクシング，ボクシング)，(バレエ，バレエ)である．

\paragraph{じゃんけん}
エージェントの集合を$\mathcal{N} = \{1, 2\}$，行動集合を${\cal A}_1 = {\cal A}_2 = \{グー, チョキ, パー\}$，利得を
\begin{table}[H]
\centering
  \begin{tabular}{c|c|c|c}
        & グー & チョキ & パー  \\ \hline
    グー & $0, 0$ & $1, -1$ & $-1, 1$  \\ \hline
    チョキ & $-1, 1$ & $0, 0$ & $1, -1$ \\ \hline
    パー & $1, -1$ & $-1, 1$ & $0, 0$ \\
  \end{tabular}
\end{table}
とする．

最適反応は，「グー」に対して「パー」，「チョキ」に対して「グー」，「パー」に対して「チョキ」である．よって，ナッシュ均衡は存在しない．

\section{混合戦略}
ここまでのゲームの定義は，エージェントがある行動を確率1で取る(純粋戦略)というものだった．ここでは，エージェントが行動集合からある確率で行動を選択するもの(混合戦略)における最適反応およびナッシュ均衡を定義する．

\subsection{混合戦略}
エージェント$i$の行動集合を${\cal A}_i = \{1, \ldots, m_i\}$とし，エージェント$i$が行動$j \in {\cal A}_i$をとる確率を並べたベクトルを$x_i = (x_i^1, \ldots, x_i^{m_i})^{\mathrm{T}}$とする．この$x_i$を混合戦略という．混合戦略$x_i$の集合
\begin{equation}
  X_i = \left\{x_i \, \left| \, \forall j \in {\cal A}_i \, x_i^{j} \geq 0, \, \sum_{k \in {\cal A}_i} x_i^{k} = 1\right.\right\} \nonumber
\end{equation}
は行動集合${\cal A}_i$上の確率分布である．この$X_i$は単位ベクトル$e_{m_i}^j$を頂点とする$m_i - 1$次元単位単体となる．

エージェント$i$の行動集合${\cal A}_i$が${\cal A}_i = \{1, 2\}$の例を考える($m_i = 2$)．混合戦略を$x_i = (x_i^1, x_i^2)^{\mathrm{T}}$とすると，混合戦略$x_i$は，
線分$x_i^1 + x_i^2 = 1, \; 0 \leq x_i^1, x_i^2 \leq 1$上の点である(図\ref{fig:mixed})．
つまり，エージェント$i$の混合戦略の集合は，
\begin{equation}
  X_i = \{(x_i^1, 1 - x_i^1)^{\mathrm{T}} \, | \, 0 \leq x_i^1 \leq 1\} \nonumber
\end{equation}
と表される．
\begin{figure}[htb]
  \centering
  \includegraphics[clip, width=5cm]{./fig/graph_1.pdf}
  \caption{$1$次元単位単体(線分)}
  \label{fig:mixed}
\end{figure}


各エージェント$i$の混合戦略の集合$X_i$の直和
\begin{equation}
  X = \times_{i \in N} X_i \nonumber
\end{equation}
を混合戦略空間という．また，
\begin{itemize}
  \item $x \in X$
  \begin{itemize}
    \item 混合戦略プロファイル．
  \end{itemize}
  \item $C(x_i) = \{j \in {\cal A}_i \, | \, x_i^j > 0\}$
  \begin{itemize}
    \item $x_i \in X_i$のキャリア．
    \item 実際に使われる可能性のある行動の集合．
  \end{itemize}
\end{itemize}
である．

混合戦略の集合$X_i$について，
\begin{equation}
  \mathrm{int}(X_i) = \{x_i \in X_i, \, | \, \forall j \in {\cal A}_i \; x_i^j > 0\} \nonumber
\end{equation}
を$X_i$の内部といい\footnote{つまり，内部はキャリアと行動集合が一致するような混合戦略の集合である．}，
\begin{equation}
  \mathrm{bd}(X_i) = \{x_i \in X_i \, | \, x_i \notin \mathrm{int}(X_i)\} \nonumber
\end{equation}
を$X_i$の境界という．$x_i \in \mathrm{int}(X_i)$を完全混合戦略(内部戦略)といい，$x \in \mathrm{int}(X) = \times_{i \in N} \mathrm{int}(X_i)$を完全混合プロファイル(内部プロファイル)という．

図\ref{fig:mixed}において，点$(x_i^1, x_i^2)^{\mathrm{T}} = (1, 0)^{\mathrm{T}}, \, (0, 1)^{\mathrm{T}}$は境界であり，それ以外の点は内部である．

\subsection{期待効用理論}
非協力ゲームにおいて，エージェントは期待利得を最大化しょうとする．戦略プロファイル$x \in X$で，行動プロファイル$a \in {\cal A}$が実際に起こる確率$x(a)$は，
\begin{equation}
  x(a) = \prod_{i \in \mathcal{N}} x_i^{a_i} \label{eq:xa}
\end{equation}
である．\eqref{eq:xa}は，エージェント$i \in \mathcal{N}$が行動$a_i \in A_i$を取る確率が$x_i^{a_i}$であり，行動プロファイル$a = (a_1, \ldots, a_n)$が起こる確率はこの積で表されることを示している．

エージェント$i$の利得の期待値を期待利得という．エージェント$i$の期待利得関数$u_i: X \to \mathbb{R}$は以下で定義される．
\begin{align}
  u_i(x) &\coloneqq x(a)U_i(a) \label{eq:def_exputil} \\
  &= \sum_{j \in A_i} x_i^j u_i(e_{m_i}^j, x_{-i}) \label{eq:exputil_sum}
\end{align}
\eqref{eq:def_exputil}は，エージェント$i$の期待利得が，エージェント$i$の利得の期待値であるという期待利得の定義である．\eqref{eq:exputil_sum}は，各エージェントの混合戦略に関して，各エージェントの期待利得は線形性を持つことを示している．
\subsection{戦略型ゲームの混合拡大}
混合拡大した戦略型ゲームは，以下のように定義される．
\begin{screen}
  \begin{defi}[戦略型ゲーム]
  戦略型ゲーム$G = (\mathcal{N}, X, u)$は次の3要素で定義される．
  \begin{itemize}
    \item $\mathcal{N} = \{1, 2, \ldots, n\}$
    \begin{itemize}
      \item エージェントの集合．
    \end{itemize}
    \item $X = \times_{i \in N} X_i$
    \begin{itemize}
      \item 混合戦略空間
      \begin{equation}
        X_i = \left\{x_i \, \left| \, \forall j \in \mathcal{A}_i \, x_i^j \geq 0, \sum_{k \in \mathcal{A}_i} x_i^k = 1\right.\right\} \nonumber
      \end{equation}
    \end{itemize}
    \item $u \, : \, X \rightarrow \mathbb{R}^n$
    \begin{itemize}
      \item 混合戦略プロファイル$x \in S$に対して，利得ベクトル
      $u(x) = (u_1(x), u_2(x), \ldots, u_n(x))$
      を割り当てる．
    \end{itemize}
  \end{itemize}
  \end{defi}
\end{screen}

特に，2人ゲームのときは利得行列$(A, B)$によってゲームが表現される．
\begin{align}
  u_1(x) &= \sum_{j \in \mathcal{A}_1} x_1^j u_1(e_{m_1}^j, x_2) = \sum_{j \in \mathcal{A}_1} \sum_{k \in \mathcal{A}_2} x_1^j x_2^k a_{jk} = x_1^{\mathrm{T}}Ax_2 \nonumber \\
  u_2(x) &= \sum_{j \in \mathcal{A}_1} \sum_{k \in \mathcal{A}_2} x_1^j x_2^k b_{kj} = x_2^{\mathrm{T}} B x_1 \nonumber
\end{align}
ここからも分かるように，純粋戦略は，ある戦略を確率1でとるものであると解釈できる．

\section{最適反応とナッシュ均衡}
\subsection{最適反応}
\begin{screen}
  \begin{defi}[最適反応]
    $a_i^{*} \in \beta(x)$を$x_{-i}$に対する純粋戦略最適反応，$x_i^{*} \in \tilde{\beta}(x)$を$x_{-i}$に対する混合戦略最適反応という．ただし，純粋戦略最適反応対応$\beta_i: X \to 2^{\mathcal{A}_i}$は
    \begin{align}
      \beta_i(x) = \{j \in \mathcal{A}_i \, | \, \forall k \in \mathcal{A}_i \, u_i(e_{m_i}^j, x_{-i}) \geq u_i(e_{m_i}^k, x_{-i})\} \label{eq:best_reply}
    \end{align}
    で定義され，混合戦略最適反応対応$\tilde{\beta}_i: X \to 2^{X_i}$は
    \begin{align}
      \tilde{\beta}_i(x) &= \{x_i^{*} \in X_i \, | \, \forall x_i^{\prime} \in X_i \, u_i(x_i^{*}, x_{-i}) \geq u_i(x_i^{\prime}, x_{-i})\} \label{eq:b_reply_1} \\
      &= \{x_i^{*} \in X_i \, | \, \forall j \in \beta_i(x) \, {x_i^{j}}^{*} = 0\} \label{eq:b_reply_2} \\
      &= \{x_i^{*} \in X_i \, | \, C(x_i^{*}) \subseteq \beta_i(x)\} \label{eq:b_reply_3}
    \end{align}
    で定義される．
  \end{defi}
\end{screen}

純粋戦略最適反応対応は，$X$の要素に対して$\mathcal{A}_i$の部分集合を返すようなものであり，混合戦略最適反応対応は，$X$の要素に対して$X_i$の部分集合を返すようなものである．
\eqref{eq:best_reply}より，純粋戦略最適反応は，他のエージェントの混合戦略を固定した下で，期待利得が最大になるような純粋戦略である．また，\eqref{eq:b_reply_2}より，混合戦略最適反応は純粋戦略最適反応ではない行動をとる確率を0とした確率の組である．その対偶をとったものが\eqref{eq:b_reply_3}である．

$\beta_i, \tilde{\beta}_i$の結合をそれぞれ，
\begin{align}
  &\beta(x) = \times_{i \in \mathcal{N}} \beta_i(x) \subseteq \mathcal{A} \nonumber \\
  &\tilde{\beta}(x) = \times_{i \in \mathcal{N}} \tilde{\beta}_i(x) \subseteq X \nonumber
\end{align}
と表す．

\subsection{ナッシュ均衡}
ナッシュ均衡は，経済理論の基礎となっている．以下のように定義される．
\begin{screen}
  \begin{defi}[ナッシュ均衡]
    \begin{enumerate}
      \item $x^{*} \in \tilde{\beta}(x^{*})$が成り立つとき，$x^{*}$をナッシュ均衡という．
      \item 特に，$\tilde{\beta}(x^{*}) = \{x^{*}\}$が成り立つとき，$x^{*}$を強ナッシュ均衡という．
    \end{enumerate}
  \end{defi}
\end{screen}

この定義から，戦略プロファイル$x^{*} \in X$がナッシュ均衡であるとは，戦略プロファイル$x^{*} \in X$が自分自身に対する最適反応になっている，つまり，$x^{*} \in X$が混合戦略最適反応$\tilde{\beta}$の不動点であるということである．

ナッシュ均衡は，すべてのエージェントにとって，その状況が実現されたら戦略を変える動機がないという点で合理的な解である．有限ゲームでは必ず存在する．

強ナッシュ均衡は，最適反応の条件が$\forall x_i^{\prime} \neq x_i^{*}$に対して不等号で成立するものである．この均衡として得られる戦略プロファイルは純粋戦略プロファイルであり，存在しない可能性もある．

特に2人2戦略の戦略型ゲームについて，具体的にナッシュ均衡を導出する．

\end{document}
